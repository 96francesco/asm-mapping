{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Externals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import rasterio\n",
    "\n",
    "from pathlib import Path\n",
    "from pytorch_lightning import seed_everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Internal modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from asm_mapping.data.planetscope_dataset import PlanetScopeDataset\n",
    "from asm_mapping.data.sentinel1_dataset import Sentinel1Dataset\n",
    "from asm_mapping.data.fusion_dataset import FusionDataset\n",
    "from asm_mapping.data.dataset_mode import DatasetMode\n",
    "from asm_mapping.models.lit_model_standalone import LitModelStandalone\n",
    "from asm_mapping.models.lit_model_lf import LitModelLateFusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seeds\n",
    "RANDOM = 79\n",
    "seed_everything(RANDOM, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_ID = 0\n",
    "\n",
    "# Set device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(f\"cuda:{GPU_ID}\")\n",
    "    print(f\"Using GPU #{GPU_ID}: {torch.cuda.get_device_name(GPU_ID)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA not available, using CPU\")\n",
    "    \n",
    "# comment out line below if you have GPU available but it's full and prefer\n",
    "# to get the prediction examples using CPU instead \n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"/mnt/guanabana/raid/home/pasan001/asm-mapping\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PS_MODEL_PATH = f\"{BASE_DIR}/old_checkpoints/split_0/ps_standalone_split_0_epoch=31_val_f1_score=0.000.ckpt\"\n",
    "S1_MODEL_PATH = f\"{BASE_DIR}/checkpoints/split_2/s1_standalone_split_2_epoch=22_val_f1_score=0.000.ckpt\"\n",
    "# LF_MODEL_PATH = f\"{BASE_DIR}/checkpoints/split_4/lf_conc_up_split_4_epoch=63_val_f1_score=0.000.ckpt\"\n",
    "LF_MODEL_PATH = f\"{BASE_DIR}/old_checkpoints/split_4/lf_sum_down_split_4_epoch=76_val_f1_score=0.000.ckpt\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PS_DATA_PATH = f\"{BASE_DIR}/data/ps_split/split_0/testing_set\"\n",
    "S1_DATA_PATH = f\"{BASE_DIR}/data/s1_split/split_0/testing_set\"\n",
    "FUSION_DATA_PATH = f\"{BASE_DIR}/data\"\n",
    "# fixed_indices = [87, 1, 111] # indices for 3 examples to generate\n",
    "fixed_indices = [24, 76, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset parameters\n",
    "PAD = False\n",
    "TRANSFORMS = None\n",
    "STANDALONE_MODE = DatasetMode.STANDALONE\n",
    "FUSION_MODE = DatasetMode.FUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_standalone_model(checkpoint_path, in_channels=6):\n",
    "      torch.cuda.set_device(GPU_ID)\n",
    "      checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "      model = LitModelStandalone.load_from_checkpoint(checkpoint_path, \n",
    "                                                      in_channels=in_channels,\n",
    "                                                      map_location=device)\n",
    "      model.eval()\n",
    "      return model\n",
    "\n",
    "def load_fusion_model(checkpoint_path):\n",
    "      torch.cuda.set_device(GPU_ID)\n",
    "      checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "      model = LitModelLateFusion.load_from_checkpoint(checkpoint_path,\n",
    "                                                      map_location=device)\n",
    "      model.eval()\n",
    "      return model\n",
    "\n",
    "def predict_standalone(model, img_tensor):\n",
    "      with torch.no_grad():\n",
    "            img_batch = img_tensor.unsqueeze(0)\n",
    "            # ensure tensor is on the same device as model\n",
    "            img_batch = img_batch.to(device)\n",
    "            logits = model(img_batch)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            pred = (probs > model.threshold).float().squeeze().cpu().numpy()\n",
    "      return pred\n",
    "\n",
    "def predict_fusion(model, planet_tensor, s1_tensor):\n",
    "      with torch.no_grad():\n",
    "            planet_batch = planet_tensor.unsqueeze(0)\n",
    "            s1_batch = s1_tensor.unsqueeze(0)\n",
    "            # ensure tensors are on the same device as model\n",
    "            planet_batch = planet_batch.to(device)\n",
    "            s1_batch = s1_batch.to(device)\n",
    "            logits = model(planet_batch, s1_batch)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            pred = (probs > model.threshold).float().squeeze().cpu().numpy()\n",
    "      return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PlanetScope standalone model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_rgb(dataset, idx):\n",
    "      img_path = dataset.dataset[idx][0]\n",
    "      \n",
    "      with rasterio.open(img_path, 'r') as src:\n",
    "            img = src.read().astype(np.float32)\n",
    "      \n",
    "      rgb = np.zeros((img.shape[1], img.shape[2], 3))\n",
    "      for i, band_idx in enumerate([2, 1, 0]):\n",
    "            band = img[band_idx]\n",
    "            band_min, band_max = band.min(), band.max()\n",
    "            if band_max > band_min: \n",
    "                  rgb[:,:,i] = np.clip((band - band_min) / (band_max - band_min), 0, 1)\n",
    "            else:\n",
    "                  rgb[:,:,i] = 0\n",
    "      \n",
    "      return rgb\n",
    "\n",
    "def plot_ps_predictions(model, dataset, indices=None, num_examples=3):\n",
    "      if indices is None:\n",
    "            indices = random.sample(range(len(dataset)), num_examples)\n",
    "      \n",
    "      fig, axs = plt.subplots(num_examples, 3, figsize=(15, num_examples * 4))\n",
    "      \n",
    "      for i, idx in enumerate(indices):\n",
    "            img_tensor, gt_tensor = dataset[idx]\n",
    "            pred = predict_standalone(model, img_tensor)\n",
    "            \n",
    "            # get RGB for visualization\n",
    "            rgb = get_raw_rgb(dataset, idx)\n",
    "            \n",
    "            # make plots\n",
    "            axs[i, 0].imshow(rgb)\n",
    "            axs[i, 0].set_title(f\"PlanetScope RGB - Example {i+1}\")\n",
    "            axs[i, 0].axis('off')\n",
    "            \n",
    "            axs[i, 1].imshow(pred, cmap='gray')\n",
    "            axs[i, 1].set_title(f\"Model Prediction\")\n",
    "            axs[i, 1].axis('off')\n",
    "            \n",
    "            axs[i, 2].imshow(gt_tensor.numpy(), cmap='gray')\n",
    "            axs[i, 2].set_title(f\"Ground Truth\")\n",
    "            axs[i, 2].axis('off')\n",
    "      \n",
    "      plt.tight_layout()\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_dataset = PlanetScopeDataset(\n",
    "    data_dir=PS_DATA_PATH,\n",
    "    mode=STANDALONE_MODE,\n",
    "    pad=PAD,\n",
    "    transforms=TRANSFORMS,\n",
    "    split=\"split_0\" \n",
    ")\n",
    "\n",
    "try:\n",
    "    ps_model = load_standalone_model(PS_MODEL_PATH, in_channels=6)\n",
    "    print(\"PlanetScope model loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading PlanetScope model: {e}\")\n",
    "    ps_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ps_model is not None:\n",
    "    print(\"\\n## PlanetScope Standalone model predictions\")\n",
    "    plot_ps_predictions(ps_model, ps_dataset, indices=fixed_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentinel-1 standalone model prediction examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s1_rgb(dataset, idx):\n",
    "      img_path = dataset.dataset[idx][0]\n",
    "      \n",
    "      with rasterio.open(img_path, 'r') as src:\n",
    "            img = src.read().astype(np.float32)\n",
    "      \n",
    "      # Create a false color composite using VV, VH, and ratio\n",
    "      rgb = np.zeros((img.shape[1], img.shape[2], 3))\n",
    "      vv = img[0]\n",
    "      vh = img[1]\n",
    "      ratio = vv - vh  # VV/VH ratio in dB scale\n",
    "      \n",
    "      # Normalize each band for visualization\n",
    "      for i, band in enumerate([vv, vh, ratio]):\n",
    "            band_min, band_max = band.min(), band.max()\n",
    "            if band_max > band_min:\n",
    "                  rgb[:,:,i] = np.clip((band - band_min) / (band_max - band_min), 0, 1)\n",
    "            else:\n",
    "                  rgb[:,:,i] = 0\n",
    "      \n",
    "      return rgb\n",
    "\n",
    "def plot_s1_predictions(model, dataset, indices=None, num_examples=3):\n",
    "      if indices is None:\n",
    "            indices = random.sample(range(len(dataset)), num_examples)\n",
    "      \n",
    "      fig, axs = plt.subplots(num_examples, 3, figsize=(15, num_examples * 4))\n",
    "      \n",
    "      for i, idx in enumerate(indices):\n",
    "            img_tensor, gt_tensor = dataset[idx]\n",
    "            pred = predict_standalone(model, img_tensor)\n",
    "            \n",
    "            # get RGB for visualization\n",
    "            rgb = get_s1_rgb(dataset, idx)\n",
    "            \n",
    "            # make plots\n",
    "            axs[i, 0].imshow(rgb)\n",
    "            axs[i, 0].set_title(f\"Sentinel-1 RGB - Example {i+1}\")\n",
    "            axs[i, 0].axis('off')\n",
    "            \n",
    "            axs[i, 1].imshow(pred, cmap='gray')\n",
    "            axs[i, 1].set_title(f\"Model prediction\")\n",
    "            axs[i, 1].axis('off')\n",
    "            \n",
    "            axs[i, 2].imshow(gt_tensor.numpy(), cmap='gray')\n",
    "            axs[i, 2].set_title(f\"Ground truth\")\n",
    "            axs[i, 2].axis('off')\n",
    "      \n",
    "      plt.tight_layout()\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_dataset = Sentinel1Dataset(\n",
    "      data_dir=S1_DATA_PATH,\n",
    "      mode=STANDALONE_MODE,\n",
    "      pad=PAD,\n",
    "      transforms=TRANSFORMS,\n",
    "      split=\"split_0\"\n",
    ")\n",
    "\n",
    "\n",
    "try:\n",
    "      s1_model = load_standalone_model(S1_MODEL_PATH, in_channels=3)\n",
    "      print(\"Sentinel-1 model loaded successfully\")\n",
    "except Exception as e:\n",
    "      print(f\"Error loading Sentinel-1 model: {e}\")\n",
    "      s1_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if s1_model is not None:\n",
    "    print(\"\\n## Sentinel-1 Standalone model predictions\")\n",
    "    plot_s1_predictions(s1_model, s1_dataset, indices=fixed_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Late Fusion model prediction examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fusion_predictions(model, dataset, indices=None, num_examples=3):\n",
    "    if indices is None:\n",
    "        indices = random.sample(range(len(dataset)), num_examples)\n",
    "    \n",
    "    fig, axs = plt.subplots(num_examples, 4, figsize=(20, num_examples * 4))\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        planet_tensor, s1_tensor, gt_tensor = dataset[idx]\n",
    "        pred = predict_fusion(model, planet_tensor, s1_tensor)\n",
    "        \n",
    "        # Get Planet RGB\n",
    "        planet_img = planet_tensor.numpy()\n",
    "        planet_rgb = np.zeros((planet_img.shape[1], planet_img.shape[2], 3))\n",
    "        for j, band_idx in enumerate([2, 1, 0]):  # RGB bands\n",
    "            band = planet_img[band_idx]\n",
    "            planet_rgb[:,:,j] = np.clip((band - band.min()) / (band.max() - band.min()), 0, 1)\n",
    "        \n",
    "        # Get S1 composite\n",
    "        s1_img = s1_tensor.numpy()\n",
    "        s1_composite = np.zeros((s1_img.shape[1], s1_img.shape[2], 3))\n",
    "        for j, band_idx in enumerate([0, 1, 2]):  # VV, VH, ratio\n",
    "            band = s1_img[band_idx]\n",
    "            s1_composite[:,:,j] = np.clip((band - band.min()) / (band.max() - band.min()), 0, 1)\n",
    "        \n",
    "        # Make plots\n",
    "        axs[i, 0].imshow(planet_rgb)\n",
    "        axs[i, 0].set_title(f\"PlanetScope RGB - Example {i+1}\")\n",
    "        axs[i, 0].axis('off')\n",
    "        \n",
    "        axs[i, 1].imshow(s1_composite)\n",
    "        axs[i, 1].set_title(f\"Sentinel-1 RGB\")\n",
    "        axs[i, 1].axis('off')\n",
    "        \n",
    "        axs[i, 2].imshow(pred, cmap='gray')\n",
    "        axs[i, 2].set_title(f\"Model prediction\")\n",
    "        axs[i, 2].axis('off')\n",
    "        \n",
    "        axs[i, 3].imshow(gt_tensor.numpy(), cmap='gray')\n",
    "        axs[i, 3].set_title(f\"Ground truth\")\n",
    "        axs[i, 3].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_dataset = FusionDataset(\n",
    "    data_dir=FUSION_DATA_PATH,\n",
    "    split=0,\n",
    "    transforms=TRANSFORMS,\n",
    "    pad=PAD,\n",
    "    is_test=True\n",
    ")\n",
    "\n",
    "try:\n",
    "    lf_model = load_fusion_model(LF_MODEL_PATH)\n",
    "    print(\"Late Fusion model loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading Late Fusion model: {e}\")\n",
    "    lf_model = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if lf_model is not None:\n",
    "    print(\"\\n## Late Fusion model predictions\")\n",
    "    plot_fusion_predictions(lf_model, fusion_dataset, indices=fixed_indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
